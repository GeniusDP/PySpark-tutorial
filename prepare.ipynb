{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = \"/home/zaranik/.sdkman/candidates/spark/current\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+-------+--------+--------+---------+---------+-----------+----------------+----------------+\n",
      "| id|presence|northing|easting|altitude|distance|NoOfPools|NoOfSites|     avrain|         meanmin|         meanmax|\n",
      "+---+--------+--------+-------+--------+--------+---------+---------+-----------+----------------+----------------+\n",
      "|  2|       1|     115|   1047|    1500|     500|      232|        3|      155.0|3.56666666666667|            14.0|\n",
      "|  3|       1|     110|   1042|    1520|     250|       66|        5|157.6666667|3.46666666666667|            13.8|\n",
      "|  4|       1|     112|   1040|    1540|     250|       32|        5|159.6666667|             3.4|            13.6|\n",
      "|  5|       1|     109|   1033|    1590|     250|        9|        5|      165.0|             3.2|13.1666666666667|\n",
      "|  6|       1|     109|   1032|    1590|     250|       67|        5|      165.0|             3.2|13.1666666666667|\n",
      "|  7|       1|     106|   1018|    1600|     500|       12|        4|167.3333333|3.13333333333333|13.0666666666667|\n",
      "|  8|       1|     105|   1015|    1600|     250|       30|        3|167.3333333|             3.1|13.0666666666667|\n",
      "|  9|       1|      84|   1014|    1560|     750|       13|        2|      165.0|             3.3|            13.4|\n",
      "| 10|       1|      88|   1023|    1560|     250|        4|        3|      164.0|             3.3|13.4333333333333|\n",
      "| 11|       1|      91|   1025|    1560|     250|       14|        4|      164.0|             3.3|13.4333333333333|\n",
      "| 12|       1|     105|   1037|    1580|     500|        9|        5|164.3333333|3.23333333333333|13.2666666666667|\n",
      "| 13|       1|     110|   1047|    1520|     500|       11|        3|157.6666667|3.46666666666667|            13.8|\n",
      "| 14|       1|      98|   1019|    1460|     750|        7|        7|153.3333333|3.66666666666667|            14.3|\n",
      "| 15|       1|      91|   1018|    1510|     250|       16|        5|      159.0|             3.5|13.8666666666667|\n",
      "| 16|       1|      89|   1020|    1520|     250|       10|        5|160.3333333|3.46666666666667|13.7666666666667|\n",
      "| 17|       1|     198|   1090|    1320|     500|       24|        4|      129.0|             4.1|            15.7|\n",
      "| 18|       1|     197|   1086|    1320|     500|        8|        2|129.3333333|             4.1|            15.7|\n",
      "| 19|       1|     190|   1119|    1300|     500|        6|        5|      127.0|4.23333333333333|15.8333333333333|\n",
      "| 20|       1|     194|   1117|    1300|     250|       19|        5|126.3333333|4.23333333333333|15.8666666666667|\n",
      "| 21|       1|     192|   1100|    1320|     250|       20|        6|129.3333333|4.13333333333333|            15.7|\n",
      "+---+--------+--------+-------+--------+--------+---------+---------+-----------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/01 21:29:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , pres.abs, northing, easting, altitude, distance, NoOfPools, NoOfSites, avrain, meanmin, meanmax\n",
      " Schema: id, pres.abs, northing, easting, altitude, distance, NoOfPools, NoOfSites, avrain, meanmin, meanmax\n",
      "Expected: id but found: \n",
      "CSV file: file:///home/zaranik/spark-tutorial/tutorial/labs/frogs.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "spark = SparkSession.builder.appName(\"lab1-frogs\").getOrCreate()\n",
    "# Define the schema for the data\n",
    "frog_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"pres.abs\", IntegerType(), False),\n",
    "    StructField(\"northing\", IntegerType(), False),\n",
    "    StructField(\"easting\", IntegerType(), False),\n",
    "    StructField(\"altitude\", IntegerType(), False),\n",
    "    StructField(\"distance\", IntegerType(), False),\n",
    "    StructField(\"NoOfPools\", IntegerType(), False),\n",
    "    StructField(\"NoOfSites\", IntegerType(), False),\n",
    "    StructField(\"avrain\", DoubleType(), False),\n",
    "    StructField(\"meanmin\", DoubleType(), False),\n",
    "    StructField(\"meanmax\", DoubleType(), False)\n",
    "])\n",
    "\n",
    "frogs_df = spark.read.csv(\"./frogs.csv\", header=True, schema=frog_schema)\n",
    "frogs_df = frogs_df.withColumnRenamed(\"pres.abs\", \"presence\")\n",
    "frogs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|max(altitude)|\n",
      "+-------------+\n",
      "|         1700|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = frogs_df.filter(frogs_df[\"presence\"] == 1).agg({\"altitude\": \"max\"})\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Вивести всі висоти, де середні максимальні температури не\n",
    "перевищують 14 градусів і на яких спостерігались жаби."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+\n",
      "|altitude|         meanmax|\n",
      "+--------+----------------+\n",
      "|    1510|13.8666666666667|\n",
      "|    1520|13.8666666666667|\n",
      "|    1520|            13.8|\n",
      "|    1520|            13.8|\n",
      "|    1530|            13.8|\n",
      "|    1520|13.7666666666667|\n",
      "|    1540|13.7333333333333|\n",
      "|    1540|13.6666666666667|\n",
      "|    1540|            13.6|\n",
      "|    1560|13.5333333333333|\n",
      "|    1560|13.5333333333333|\n",
      "|    1560|13.4333333333333|\n",
      "|    1560|13.4333333333333|\n",
      "|    1560|            13.4|\n",
      "|    1580|            13.4|\n",
      "|    1580|            13.3|\n",
      "|    1580|13.2666666666667|\n",
      "|    1600|            13.2|\n",
      "|    1600|            13.2|\n",
      "|    1590|13.1666666666667|\n",
      "+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = frogs_df.filter(frogs_df[\"presence\"] == 1).filter(frogs_df[\"meanmax\"] < 14).orderBy(frogs_df[\"meanmax\"].desc())\n",
    "df.select(\"altitude\", \"meanmax\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
