{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lab6: Задачі регресії в Spark MLlib</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "os.environ['SPARK_HOME'] = \"/home/zaranik/.sdkman/candidates/spark/current\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Створення Spark-сессії"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLLib\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задання схеми даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"week_ending\", StringType(), True),\n",
    "    StructField(\"week_number\", IntegerType(), True),\n",
    "    StructField(\"weekly_gross_overall\", IntegerType(), True),\n",
    "    StructField(\"show\", StringType(), True),\n",
    "    StructField(\"theatre\", StringType(), True),\n",
    "    StructField(\"weekly_gross\", IntegerType(), True),\n",
    "    StructField(\"potential_gross\", StringType(), True),  # NA is treated as StringType\n",
    "    StructField(\"avg_ticket_price\", DoubleType(), True),\n",
    "    StructField(\"top_ticket_price\", StringType(), True),  # NA is treated as StringType\n",
    "    StructField(\"seats_sold\", IntegerType(), True),\n",
    "    StructField(\"seats_in_theatre\", IntegerType(), True),\n",
    "    StructField(\"pct_capacity\", DoubleType(), True),\n",
    "    StructField(\"performances\", IntegerType(), True),\n",
    "    StructField(\"previews\", IntegerType(), True),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зчитування даних з файлу csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"./data/grosses.csv\", header=True, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функція для виведення результатів оцінки точності моделювання"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prescision(predictions):\n",
    "  from pyspark.ml.evaluation import RegressionEvaluator\n",
    "  # Evaluate the Model\n",
    "  evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "  # Calculate Metrics\n",
    "  mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n",
    "  mse = evaluator.evaluate(predictions, {evaluator.metricName: \"mse\"})\n",
    "  rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
    "  r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "  return mae, mse, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функція побудови регрессії"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(num_trees, max_depth):\n",
    "  from pyspark.ml.feature import VectorAssembler\n",
    "  from pyspark.ml.regression import RandomForestRegressor\n",
    "    \n",
    "  assembler = VectorAssembler(\n",
    "      inputCols=[\"seats_sold\", \"avg_ticket_price\", \"seats_in_theatre\", \"pct_capacity\"],  # Independent variables\n",
    "      outputCol=\"features\"\n",
    "  )\n",
    "\n",
    "  df_prepared = assembler.transform(df).select(\"features\", \"weekly_gross\")\n",
    "  df_prepared = df_prepared.withColumnRenamed(\"weekly_gross\", \"label\")  # Rename target column to 'label'\n",
    "  df_prepared = df_prepared.filter(\"label IS NOT NULL AND NOT isnan(label)\")\n",
    "\n",
    "  # Initialize LinearRegression\n",
    "  lr = RandomForestRegressor(numTrees=num_trees, maxDepth=max_depth)\n",
    "\n",
    "  # Explain Parameters\n",
    "  # print(lr.explainParams())\n",
    "\n",
    "  # Fit the Model\n",
    "  lr_model = lr.fit(df_prepared)\n",
    "\n",
    "  # Make Predictions\n",
    "  prescisions = lr_model.transform(df_prepared)\n",
    "  mae, mse, rmse, r2 = evaluate_prescision(prescisions)\n",
    "  \n",
    "  print(\"*********************************************************\")\n",
    "  print(f\"Prediction for readmon forest with num_trees = {num_trees}, max_depth = {max_depth} evalution results: \")\n",
    "  print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "  print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "  print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "  print(f\"R-squared (R²): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(10, 5)\n",
    "get_predictions(25, 7)\n",
    "get_predictions(50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
